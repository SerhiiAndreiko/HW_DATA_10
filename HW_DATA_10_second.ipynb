{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPPtgHqpWq0rRu8sME7ZHDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerhiiAndreiko/HW_DATA_10/blob/main/HW_DATA_10_second.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Частина 2**\n",
        "\n",
        "​\n",
        "\n",
        "В цій частині ми знову будемо працювати з датасетом fasion_mnist.\n",
        "\n",
        "\n",
        "\n",
        "На відміну від попереднього завдання вам пропонується створити згорткову нейромережу, що використовує VGG16 в якості згорткової основи.\n",
        "\n",
        "\n",
        "\n",
        "Навчіть отриману мережу на даних із датасету fasion_mnist. Спробуйте досягти максимально можливої точності класифікації за рахунок маніпуляції параметрами мережі. Під час навчання використовуйте прийоми донавчання та виділення ознак.\n",
        "\n",
        "\n",
        "\n",
        "Порівняйте точність отриманої згорткової мережі з точністю багатошарової мережі з попереднього завдання. Зробіть висновки."
      ],
      "metadata": {
        "id": "dLQ-0hzQqjk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from skimage import color\n",
        "\n",
        "# Завантаження даних Fashion MNIST\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Додавання додаткового каналу\n",
        "train_images = np.expand_dims(train_images, axis=-1)\n",
        "test_images = np.expand_dims(test_images, axis=-1)\n",
        "\n",
        "# Конвертація в колірне зображення (3 канали)\n",
        "train_images = np.repeat(train_images, 3, axis=-1)\n",
        "test_images = np.repeat(test_images, 3, axis=-1)\n",
        "\n",
        "# Нормалізація даних\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "# Завантаження моделі VGG16 без верхніх повнозв'язних шарів\n",
        "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(28, 28))\n",
        "\n",
        "# Замороження ваг моделі VGG16\n",
        "vgg_base.trainable = False\n",
        "\n",
        "# Побудова згорткової мережі\n",
        "model = Sequential([\n",
        "    vgg_base,\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Компіляція моделі\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Навчання моделі\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "history_vgg = model.fit(train_images, train_labels, epochs=20, batch_size=64, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Оцінка моделі на тестових даних\n",
        "test_loss_vgg, test_acc_vgg = model.evaluate(test_images, test_labels)\n",
        "print('Точність на тестових даних VGG16:', test_acc_vgg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TLTy-4bPqmgg",
        "outputId": "fbf5029d-9d42-4dcf-d68b-afff49502522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "`input_shape` must be a tuple of three integers.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-a83ab820073a>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Завантаження моделі VGG16 без верхніх повнозв'язних шарів\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mvgg_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Замороження ваг моделі VGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/vgg16.py\u001b[0m in \u001b[0;36mVGG16\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m    135\u001b[0m         )\n\u001b[1;32m    136\u001b[0m     \u001b[0;31m# Determine proper input shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     input_shape = imagenet_utils.obtain_input_shape(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mdefault_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/applications/imagenet_utils.py\u001b[0m in \u001b[0;36mobtain_input_shape\u001b[0;34m(input_shape, default_size, min_size, data_format, require_flatten, weights)\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    399\u001b[0m                         \u001b[0;34m\"`input_shape` must be a tuple of three integers.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m                     )\n",
            "\u001b[0;31mValueError\u001b[0m: `input_shape` must be a tuple of three integers."
          ]
        }
      ]
    }
  ]
}